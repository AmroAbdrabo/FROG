h2. Highlights (20%)

Audience response systems (ARS) or clickers, as they are commonly called, offer a management tool for engaging students in the large classroom. Basic elements of the technology are discussed. These systems have been used in a variety of fields and at all levels of education. Typical goals of ARS questions are discussed, as well as methods of compensating for the reduction in lecture time that typically results from their use. Examples of ARS use occur throughout the literature and often detail positive attitudes from both students and instructors, although exceptions do exist. When used in classes, ARS clickers typically have either a benign or positive effect on student performance on exams, depending on the method and extent of their use, and create a more positive and active atmosphere in the large classroom. These systems are especially valuable as a means of introducing and monitoring peer learning methods in the large lecture classroom. So that the reader may use clickers effectively in his or her own classroom, a set of guidelines for writing good questions and a list of best-practice tips have been culled from the literature and experienced users. [[skimx://caldwell2007clickers#1|p. 1]]

Uses of this technology vary widely and include spicing up standard lecture classes with periodic breaks, assessing student opinions or understanding related to lecture, increasing the degree of interactivity in large classrooms, conducting experiments on human responses (e.g., in psychology courses), and managing cooperative learning activities. [[skimx://caldwell2007clickers#1|p. 1]]

many researchers and educators assert their great potential for improving student learning (Beatty et al., 2006). [[skimx://caldwell2007clickers#1|p. 1]]

The literature on applications and classroom outcomes of ARS use includes not only descriptive articles but also quantitative educational research studies with varying degrees of rigor (for reviews see Roschelle et al., 2004a; McDermott and Redish, 1999; Duncan, 2005; Simpson and Oliver, 2006). [[skimx://caldwell2007clickers#1|p. 1]]

Although this article focuses mainly on the use of AR systems in large lecture courses, instructors have reported using clickers in classes ranging from 15 students (e.g., Draper, 2002) to more than 200 students (e.g., Cue, 1998; Draper and Brown, 2002; Wit, 2003). Although much of the early research and development of clickers was done by physics instructors, a creative or willing instructor can apply the technology to virtually any subject. ARS technology has been incorporated into courses in nursing (Halloran, 1995), communication (Jackson and Trees, 2003), engineering (van Dijk et al., 2001; d’Inverno et al., 2003), computer science (Draper, 2002; Draper and Brown, 2002; d’Inverno et al., 2003; Roschelle et al., 2004a), mathematics (Mays, personal communication1; Draper and Brown, 2002; Wit, 2003; Roschelle et al., 2004a; Caldwell et al., 2006), chemistry (Roschelle et al., 2004a; Bunce et al., 2006), philosophy (Draper and Brown, 2002), biology (McGraw, personal communication2; Draper, 2002; Draper and Brown, 2002; Brewer, 2004; Roschelle et al., 2004a; Wood, 2004; Hatch and Jensen, 2005; Knight and Wood, 2005), physics (Cue, 1998; Poulis et al., 1998; Dufresne et al., 2000; Burnstein and Lederman, 2001; Lindenfeld, 2001; Hake, 2002; Roschelle et al., 2004a; Pollock, 2005, 2006; Beatty et al., 2006), premedical education (Roschelle et al., 2004a), medical, veterinary, and dental education (Draper, 2002; Draper and Brown, 2002), business (Cue, 1998; Roschelle et al., 2004a; Beekes, 2006), economics (Simpson and Oliver, 2006), and psychology (Draper, 2002; Draper and Brown, 2002). [[skimx://caldwell2007clickers#2|p. 2]]

ARS technology has been successfully used in varied course formats, ranging from optional tutorials (d’Inverno et al., 2003) to formal standard lectures and cooperative learning through peer instruction (Nichol and Boyle, 2003). [[skimx://caldwell2007clickers#2|p. 2]]

Modes of implementation are as varied as the instructors who use them, but typically between two and five questions are given per 50 minutes of class instruction (e.g., Burnstein and Lederman, 2001; Elliot, 2003; Jackson and Trees, 2003; Beatty, 2004; Caldwell et al., 2006). [[skimx://caldwell2007clickers#2|p. 2]]

There are many types of questions, but some common features have been noted (e.g., Poulis et al., 1998; Draper et al., 2002, Simpson and Oliver, 2006). Among the common uses of clicker questions are the following: [[skimx://caldwell2007clickers#2|p. 2]]

1. toincreaseormanageinteraction,throughquestionsthat: 
  *  start or focus discussions (Jackson and Trees, 2003) 
  *  require interaction with peers (Knight and Wood, 2005) 
  *  collect votes after a debate (Draper, 2002) 2. to assess student preparation and ensure accountability, through: [[skimx://caldwell2007clickers#2|p. 2]]


  *  questions about reading or homework (Knight and Wood, 2005) 
  *  prelab questions 3. to find out more about students, by: 
  *  surveying students’ thoughts about the pace, effectiveness, style, or topic of lecture 
  *  polling student opinions or attitudes 
  *  probing students’ pre-existing level of understanding 
  *  asking how students feel about clickers and/or active learning 4. for formative (i.e., diagnostic) assessment, through questions that: 
  *  assess students’ understanding of material in lecture 
  *  reveal student misunderstandings of lecture (e.g., Wood, 2004) 
  *  determine future direction of lecture, including the level of detail needed 
  *  test students’ understanding of previous lecture notes 
  *  assess students’ ability to apply lecture material to a new situation 
  *  determine whether students are ready to continue after working a problem (Poulis et al., 1998) 
  *  allow students to assess their own level of understanding at the end of a class (Halloran, 1995) [[skimx://caldwell2007clickers#3|p. 3]]

Many of the courses that use clickers have abandoned lecture altogether or at least reduced it to a smaller component of class time (Draper et al., 2002; Cutts et al., 2004; Knight and Wood, 2005). [[skimx://caldwell2007clickers#3|p. 3]]

for quizzes or tests (Draper, 2002) although reports of using clickers for summative high-stakes testing are relatively rare. Quiz questions typically check whether students are: 
  *  paying attention 
  *  taking good notes 
  *  preparing for class or labs 
  *  keeping up with homework 
  *  actively thinking 
  *  able to recall material from previous lectures 6. to do practice problems, especially in math, chemistry, engineering, or physics courses 7. to guide thinking, review, or teach, including questions used to: 
  *  review at the end of lecture 
  *  give prelab tutorials (Draper, 2002) 
  *  review for a test (Jackson and Trees, 2003) 
  *  lead students through a multistep process by asking which step should come next (Wood, 2004) 8. to conduct experiments on or illustrate human responses (Draper et al., 2002; Simpson and Oliver, 2006) 9. to make lecture fun. [[skimx://caldwell2007clickers#3|p. 3]]

These methods of sampling class opinion, unfortunately, are vulnerable to small sample size problems: a small but vocal minority can give the impression that the silent majority of the class understands (or misunderstands) a topic (Simpson and Oliver, 2006). [[skimx://caldwell2007clickers#3|p. 3]]

As an example, some less common but innovative uses include: 
  *  using an ARS as a “clapometer” to continuously monitor in real time whether students are confused (Cutts et al., 2004) 
  *  using an ARS for “differentiated instruction” to track the level of understanding and progress in a small class with unevenly distributed abilities (Parsons, 2005) 
  *  using questions with multiple correct answers or only partially correct answers to prompt discussion (Burnstein and Lederman, 2001). [[skimx://caldwell2007clickers#3|p. 3]]

Instructors can instead use other equally low-tech methods to ask the entire class a question and collect responses by “show-of-hands” votes, applause or other audible feedback, [[skimx://caldwell2007clickers#3|p. 3]]

Dr. Wiedemeier randomly chooses a different small group of students each day, designated “Wied’s Wonderful,” from her large lecture course of more than 300 students. These students answer questions and are designated the “volunteers” (as needed) during the current class meeting for extra credit. [[skimx://caldwell2007clickers#3|p. 3]]

and prefabricated response cards that indicate a vote with various colors, shapes, or words (Heward et al., 1996). However, these low-tech methods, although less expensive, have several disadvantages. The lack of privacy during voting may prevent completely honest votes, time constraints may preclude accurate estimates, and (aside from the applause method) the overall trend of student responses is only truly apparent to the instructor. [[skimx://caldwell2007clickers#4|p. 4]]

A wealth of journal articles explore the uses, outcomes, and benefits of clicker use, and some good reviews exist (McDermott and Redish, 1999; Roschelle et al., 2004a; Duncan, 2005; Simpson and Oliver, 2006). [[skimx://caldwell2007clickers#5|p. 5]]

Most reviews agree that “ample converging evidence” suggests that clickers generally cause improved student outcomes such as improved exam scores or passing rates, student comprehension, and learning and that students like clickers. The reviews of the literature, however, also agree that much of the research so far is not systematic enough to permit scientific conclusions about what causes the benefits (Roschelle et al., 2004a, 2004b; Simpson and Oliver, 2006). It is possible that the alteration of teaching methods associated with clickers is responsible, rather than the use of clickers themselves. It is also possible that a “Hawthorne Effect” (Mayo, 1977) is responsible: the treatment of our student “test subjects” is different when we use clickers, and this special treatment causes the improvement rather than the use of clickers. This explanation seems less likely when the systems have been used several times by an instructor and are thus no longer novel (Poulis et al., 1998), but a Hawthorne effect is difficult to rule out. [[skimx://caldwell2007clickers#5|p. 5]]

A tentative explanation (Poulis et al., 1998) for positive effects of clickers on student achievement suggests several factors: 
  *  increased active participation of students during lecture 
  *  removal of the “house of cards effect,” in which students understand new material poorly because it is based on other poorly understood material 
  *  use of discussions and peer learning in many implementations. [[skimx://caldwell2007clickers#5|p. 5]]

For clicker research to proceed rapidly in a variety of fields, good standardized tests that assess student understanding of concepts would be helpful to evaluate the effect of various instructional methods (Hake, 2002). Such exams do exist in physics, astronomy, and economics, but are only slowly becoming available in other fields (Anderson et al., 2002; Hake, 2002; Klymkowsky et al., 2003). [[skimx://caldwell2007clickers#5|p. 5]]

An instructive example comes from Belfast (Burns, 1985): Students given transcripts of lectures and asked not to attend class produced better notes and achieved higher test scores than students who did attend the lecture class (but were not given the transcript)—as long as the class was lecture only. [[skimx://caldwell2007clickers#6|p. 6]]

Just-in-Time-Teaching (JiTT) offers another alternative: Web-based classroom management systems are used to give students “warm up exercises” outside of class and to hold them responsible for learning material before class; class time is used to refine and apply those understandings (Novak et al., 1999; Marrs and Novak, 2004; Smith et al., 2005). [[skimx://caldwell2007clickers#6|p. 6]]

An underlying assumption noted in much of the literature on clicker usage is the conviction that covering content is not the most effective way to teach and that active engagement leads to more effective learning (Draper et al., 2002; Cutts et al., 2004; Knight and Wood, 2005; Simpson and Oliver, 2006). [[skimx://caldwell2007clickers#6|p. 6]]

Several texts exist to help a new user of clickers get started (Mazur, 1997; Duncan, 2005). [[skimx://caldwell2007clickers#8|p. 8]]

Planning [[skimx://caldwell2007clickers#8|p. 8]]

Attendance [[skimx://caldwell2007clickers#8|p. 8]]

Communication with Students [[skimx://caldwell2007clickers#8|p. 8]]

Peer Learning [[skimx://caldwell2007clickers#9|p. 9]]

Grades and Anxiety [[skimx://caldwell2007clickers#9|p. 9]]

Prevent Wasted Time and Frustration [[skimx://caldwell2007clickers#9|p. 9]]

There is general agreement that a good clicker question is different from a good exam question, but exam questions can be modified for this use (Beatty et al., 2006). Some detailed treatments of question design are available in the literature (e.g., Beatty et al., 2006). Generally speaking, qualitative questions (that avoid calculations, memorization, or facts) are favored because they guide the student to focus on the concept without becoming distracted by details (Beatty, 2004; Beatty et al., 2006). [[skimx://caldwell2007clickers#9|p. 9]]

Other Survival Tips [[skimx://caldwell2007clickers#9|p. 9]]

Some examples of questions recommended by the literature include (Dufresne et al., 2000; Wit, 2003): 
  *  given a term or concept, identify the correct definition from a list, and vice versa 
  *  given a graph, match it with the best description or interpretation, and vice versa 
  *  match a method of analysis with an appropriate data set, and vice versa 
  *  questions that link the general to the specific 
  *  questions that share a familiar situation or example with several other questions 
  *  questions that students cannot answer, to motivate discussion and curiosity before introducing a new topic 
  *  questions that require ideas or steps to be sorted into order 
  *  questions that list steps and ask “which one is wrong?” 
  *  questions that apply a familiar idea to a new context. [[skimx://caldwell2007clickers#10|p. 10]]

Peer learning has attracted a high level of interest—-especially in the physics education community—because peer learning and other active learning methods have been demonstrated to result in higher learning gains and/or exam scores than more traditional, content-based approaches to course material such as lecture (MacManaway, 1970; Hake, 1998; Pollock, 2006). Although it exists in many formats, ranging from ConcepTests (tests of conceptual understanding, often alternating with mini-lectures; Mazur, 1997; Anderson et al., 2002; Udovic et al., 2002) to question cycles (Beatty et al., 2006), the overall theme of peer learning is similar: Students spend a significant portion of class time working or discussing problems in small groups. [[skimx://caldwell2007clickers#10|p. 10]]

::Nice: scripts!:: [[skimx://caldwell2007clickers#10|p. 10]]

There are two fairly distinct approaches to peer instruction that differ in when the group interaction occurs (Nichol and Boyle, 2003). The classwide discussion method (also known in the literature as the “PERG” approach) begins with a question and proceeds immediately to small-group discussion to answer it, followed by full-class discussion. The peer-learning model (also known in the literature as Peer Instruction) requires that students think and answer independently first, see the answers, and then spend time in groups struggling to reach a consensus answer. Some data indicate that the latter method works better in larger classes, because individual answers force stronger engagement, and the class discussion portion of PERG may introduce too much confusion, unless the question asked is very difficult (Nichol and Boyle, 2003). [[skimx://caldwell2007clickers#10|p. 10]]

REFERENCES [[skimx://caldwell2007clickers#11|p. 11]]


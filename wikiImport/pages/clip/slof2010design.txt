h2. Highlights

This study investigated the effects of representational scripting on non-expert student learning while collaboratively carrying out complex learning-tasks. The premise underlying this research is that effective cognitive activities would be evoked when complex learning-tasks are structured into phase-related part-tasks and are supported by providing students with part-task-congruent external representations for each phase; representational scripting. It was hypothesized that this approach would lead to increased individual learning and better complex learning-task performance. In groups, 96 secondary education students worked on a complex business-economics problem in four experimental conditions, namely one condition in which the groups received representations that were part-task-congruent for all three phases and three conditions in which the groups received one of these representations for all three phases (i.e., part-task-incongruent for two of the three phases). The results indicate that groups receiving part-task-congruent representations in a phased order performed better on the complex learning-task, though this did not result in increased individual learning. [[skimx://slof2010design#2|p. 2]]

computer technology can provide support for students collaboratively carrying out complex learning-tasks. For such learning-tasks, groups of students often carry out different kinds of activities in two different dialogue spaces. In the content space, students carry out cognitive activities to deal with the phase-related part-task such as orienting themselves to the problem, finding solutions to the problem and evaluating the solutions found. In the relational space, students carry out communicative activities such as making their own knowledge and ideas explicit to others, creating shared understanding with the other group members, and negotiating multiple perspectives with the others (Barron, 2003; Janssen, 2008). To this end, students can be: • stimulated to externalize their knowledge and ideas through chat and representational tools (e.g., Fisher, Bruhn, Gräsel, & Mandl, 2002), • provided with scaffolding for their learning through scripting and representational guidance tools that structure the learning process (Reiser, 2004, Suthers, 2006), and/or • offered offloading possibilities through the availability of storage spaces for contributions, external representations, and/or external information sources, all of which leave more working memory capacity for (part or whole) task completion (e.g., Hollan, Hutchins, & Kirsh, 2000). [[skimx://slof2010design#3|p. 3]]

These studies, though very valuable and informative, neglect the fact that complex learning-tasks are usually composed of fundamentally different phase-related part-tasks, each of which needs to be supported by different tools for them to be properly carried out (e.g., Van Bruggen, Boshuizen, & Kirschner, 2003). This is not only the case for CSCL, but is true of all complex learning-tasks. For carrying out such learning-tasks, students need to be supported in (1) dealing with the phase-related part-task demands and carrying out activities endemic to the different part-tasks in the proper sequence, (2) acquiring and applying well-suited problem representations for each part-task, and (3) combining these different problem representations into a whole (Ploetzner, Fehse, Kneser, & Spada, 1999; Spector, 2008; Van Merriënboer, Kester, & Paas, 2006; Van Merriënboer & Kirschner, 2007). [[skimx://slof2010design#3|p. 3]]

The study reported on here is aimed at designing a CSCL-environment to support students in successfully carrying out complex learning-tasks. By scripting the completion-process with representational tools (i.e., representational scripting), collaborative cognitive activities beneficial for carrying out the different part-task are evoked. The goal of this study is to determine whether integrating scripting and representational tools leads to a better use of available computer technology, and specifically whether this representational scripting affects both complex learning-task performance and individual learning gains in CSCL. In this article we speak of students, since the CSCL-environment is intended to be used in an educational setting where students learn collaboratively by carrying out complex learning-tasks, but the design of the representational scripting and its use might also be beneficial for all those involved in carrying out complex learning-tasks that have a part-task structure. [[skimx://slof2010design#3|p. 3]]

Representational scripting entails the integration of scripting and representational tools whereby the different phase-related part-tasks of a problem-solving process are made explicit and are sequenced for students which in turn leads to the evocation and application of specific problem representations. This part-task-related support is intended to guide students when carrying out complex learning-tasks, leading to more successful complex learning-task performance and better solutions. [[skimx://slof2010design#4|p. 4]]

Such scripting entails the segmentation of a complex problem in distinct phases for discussion, solution and evaluation, with distinct purposes of each phase for the problem solving process (Beers, Boshuizen, Kirschner, & Gijselaers, 2005; Dillenbourg; O’Donnell & Dansereau, 1992). The script structures the complex learning-task by dividing it into a sequence of ontologically distinct problem-phases (i.e., problem orientation, problem solution, solution evaluation) so that they can be provided with representations congruent with the part-task demands and activities required for each phase (Duffy, Dueber, & Hawley, 1998; Van Bruggen, et al., 2003). [[skimx://slof2010design#4|p. 4]]

The representational tools are meant to provide different views (i.e., problem representations) of the knowledge domain in which the complex learning-task is situated. Visualizing the domain by providing external representations (ERs) influences students’ cognitive behavior through their representational guidance (Ertl, Kopp, & Mandl, 2008; Suthers, 2006). Due to its ontology (i.e., objects, relations, and rules for combining them) every ER offers a restricted view of the domain making it easier to express certain aspects of that domain (Brna, Cox, & Good, 2001; Van Merriënboer & Kirschner, 2007). By matching the representational guidance of the ERs with the phase-related part-tasks, student understanding and part-task-specific activity should increase. However, an ER is seldom effective for all part-task demands and activities (Schnotz & Kürschner, 2008; Van Bruggen, et al., 2003). Carrying out complex learning-tasks requires students to create different perspectives of the whole learning-task (i.e., different problem representations) which necessitates providing multiple ERs to support them in creating these representations. To effectively do this, one must avoid or neutralize the difficulties students encounter when combining multiple ERs, namely problems translating from and coordinating between different kinds of representations (Ainsworth, 2006), and incongruence between representation and phase-related part-task (Vekiri, 2002). This necessitates that the representational guidance of a specific ER must be congruent (i.e., matched) with the part-task demands and activities of a specific problem phase. [[skimx://slof2010design#4|p. 4]]

Non-expert students carrying out complex learning-tasks without guidance rely primarily on surface features (i.e., using objects referred to in the problem) instead of the underlying principles of the domain, and tend to employ weak problem-solving strategies such as working via a means-ends strategy towards a solution instead of strong ones that are carefully tailored to the specific structure of the domain (Simon, Langley, & Bradshaw, 1981). An important reason for this is that these students have problems with creating and combining suitable [[skimx://slof2010design#4|p. 4]]

knowledge representations, lacking a well developed understanding required for carrying out the complex learning-task (Ploetzner, et al., 1999; Seufert, 2003). Without such an understanding, students are often not able to create a meaningful problem representation. This is problematic because the ease with which a problem can be solved often depends on the quality of the problem representation. Different problem representations initiate different kinds of operators which can act to produce new information that supports problem solvers in coming to a solution to the problem (Chi, Glaser, & Rees, 1982; Jonassen, 2003). To overcome these difficulties, students need to be made aware of the different problem phases and their required problem representations and be supported in creating and combining these representations (Ainsworth, 2006; Bredeweg & Forbus, 2003; Frederiksen & White, 2002; Ploetzner, et al., 1999). [[skimx://slof2010design#5|p. 5]]

Solving a complex problem is frequently regarded as a three-phase process, namely (1) orienting to the problem, (2) finding one or more possible problem solutions, and (3) evaluating the solutions so as to choose the best one (Duffy, et al., 1998; Van Bruggen, et al., 2003). Each of these phases requires the creation of a specific qualitative or a quantitative problem representation. Qualitative representations provide an overview of the relevant concepts and their interrelationships in the knowledge domain and/or their underlying causal principles. When the interrelationships are quantitatively specified, as is often the case in business-economics for example, students are more restricted in creating a suitable problem representation because their attention is more focused on the mathematical relationships between specific concepts. This may be detrimental for the first two phases of problem solving (i.e., problem orientation, problem solution) because it hinders them in thinking about multiple solutions. Furthermore, quantitative representations can only be understood and applied if the students have a well developed qualitative understanding of the knowledge domain. When understood, quantitative representations enable students to evaluate their proposed solutions, something qualitative representations do not allow. In the problem orientation phase, students need to construct a cognitive bridge between their initial mental model and the mental model to be created (Chi, et al., 1982; Jonassen, 2003). This phase involves a part- task which focuses on constructing a global problem representation, becoming aware of the problem itself and of the important concepts of the knowledge domain, and becoming aware of the constraints and criteria for solution [[skimx://slof2010design#5|p. 5]]

and evaluation (e.g., this concept should affect this concept and that is something that will help to achieve the goal). For creating such a problem overview, a qualitative problem representation containing the relevant concepts is more appropriate than a quantitative one for supporting students in broadening the problem space. The problem solution phase, which follows the orientation phase, is where the students apply the underlying causal principles of the knowledge domain to produce concrete solutions. The part-task in this phase is more structured than in the previous phase and focuses on combining the concepts of the domain into principles and making causal relationships between the problem and the proposed solutions explicit (e.g., if this concept is increased, then this concept decreases). Here students might create a number of possible solutions and then reason about the advantages and disadvantages of each. The main advantage of these activities is that the solutions come in a rather straightforward, often causal, way from this which makes the completion-process more efficient and effective (e.g., Jonassen & Ionas, 2008). The problem representation remains qualitative, but contains - along with the central concepts of the problem - causal information (i.e., if this, then that) which supports students in finding multiple solutions to the problem. During the third and final phase, the solution evaluation phase, it is more appropriate that students relate the solutions they arrived at to their consequences so as to determine their suitability. This should enable students to reach a final and suitable problem solution. This part-task focuses on calculating the proposed solutions and gaining insight into their quantitative effects (e.g., increasing this concept doubles that concept, but also increases it to a level that is unrealistic). [[skimx://slof2010design#6|p. 6]]

External representations (ERs) support students in creating different problem representations (i.e., qualitative and quantitative ones) through their differences in representational guidance. In order to be beneficial for problem solving it is important that the representational guidance of a specific ER is congruent with part-task demands and activities of a specific problem phase (Schnotz & Kürschner, 2008; Van Bruggen, et al., 2003). The representational guidance of an ER is provided by its ontology, which is specified through its expressiveness and processability (see Table 2). Expressiveness refers to what the ER can represent, namely concepts and their interrelationships (i.e., specificity), and how accurately they are represented (i.e., precision). Processability refers to the differences in processing the information from the ER caused by the difference in expressiveness, and which determines the number and quality of inferences that can be made. Less expressive (i.e., less specific and less precise) ERs have the advantage of being highly processable (Larkin & Simon, 1987) making it easy to make many inferences from them (i.e., elaboration). Such ERs guide students in elaborating on the concepts of the knowledge domain and in relating them to the problem (e.g., Jonassen, 2003). These ERs, however, do not have much expressive power (Cox, 1999); the inferences made from them cannot be very specific and precise. For this, the order of the ER is important. The order of an ER (Frederiksen, White, & Gutwill, 1999) determines the quality of the inferences (i.e., kind of reasoning). A zero order ER supports reasoning about concepts and in relating this reasoning to the problem in qualitative way. It is highly processable, but not very expressive. A first order ER is more expressive - and thus specific and precise - which supports reasoning about causal relationships and guides discussion and/or thought about possible solutions. A second order ER is the most expressive guide and supports quantitative inference-making enabling negotiation and/or determination of suitability of the proposed solutions. When the representational guidance of the ER is congruent with (i.e., matched to) the ontological demands of the [[skimx://slof2010design#6|p. 6]]

part-task of a problem phase, students are supported in carrying out the required part-task demands and activities of that phase. A mismatch, on the other hand, means that the ER is incongruent with the part-task and, therefore, may hinder students carrying out complex learning-tasks. Reasons for this could be that the available ER is not expressive enough because it contains only global information, or that it is too hard to process because students do not have enough prior domain knowledge to properly grasp it and make use of the ERs’ expressiveness. [[skimx://slof2010design#7|p. 7]]

::Wonder about making it too easy for students could also inhibit learning? Also - is there a general path to solving problems which could be scripted, that would also be:: [[skimx://slof2010design#7|p. 7]]

This study focuses on how the design of a CSCL-environment that scripts problem-solving behavior by providing ontologically distinct ERs affects both complex learning task-performance and individual learning gains. To this end, four experimental conditions were defined. In triads, students in all conditions had to collaboratively solve a case-based problem in business-economics which was divided into three problem phases, each coupled with different ERs. To study the effects of the representational scripting, the ERs were either matched or mismatched to the different problem phases (see Table 3). [[skimx://slof2010design#7|p. 7]]

Due to the presumed match between ERs and phase-related part-tasks, student understanding and part-task-related activity should increase, allowing them to come up with better solutions for the problem. It was, therefore, hypothesized students in the match condition (H1) create a better developed understanding (i.e., learning gains) and (H2) will [[skimx://slof2010design#7|p. 7]]

arrive at a better solution to the problem (i.e., complex learning-task performance), because their knowledge has progressively evolved from qualitative to quantitative. [[skimx://slof2010design#8|p. 8]]

::Interesting use of triads, usually always dyads.:: [[skimx://slof2010design#8|p. 8]]

Students collaborated in a CSCL-environment called Virtual Collaborative Research Institute (VCRI, see Figure 1). VCRI is a groupware application for supporting the collaborative performance of complex learning-tasks, inquiry-tasks and research projects (Jaspers, Broeken, & Erkens, 2005). For this study, five tools that are part of the VCRI were augmented with representational scripting. All tools, except the Notes tool, were shared among group members. [[skimx://slof2010design#8|p. 8]]

::Interesting to separate between private notes and public notes - similar to GroupScribbles. All students had access to all tools, difference was in which way they were guided.:: [[skimx://slof2010design#9|p. 9]]

The chat tool enables synchronous communication and supports students in externalizing and discussing their ideas and knowledge. The chat history is stored automatically and can be re-read. Students can find the description of the complex learning-task and its phase-related part-tasks in the Assignment menu. Besides this, additional information sources such as a definition list, formula list, and clues for solving the problem were also available in the assignment menu. The Co-writer is a shared text-processor where students can formulate and revise their answers to the part-tasks. The Notes tool is an individual notepad that allows students to store information and to structure their own knowledge and ideas before making them explicit. The Status bar is an awareness tool that displays which group members are logged into the system and which tool a group member is currently using. All students in all conditions had access to these tools and information sources, and were, thus, information equivalent. The conditions only differed in the way that the ERs guided the students in creating and combining different problem representations. [[skimx://slof2010design#9|p. 9]]

All groups worked on a complex business-economics problem in which they had to advise an entrepreneur about changing her/his business strategy in order to make the business more profitable (i.e., achieve a better company result). To provide a suitable advice, students had to carry out three different phase-related part-tasks, namely (1) determine the main concepts responsible for the company’s results and relate them to the problem, (2) determine how certain interventions (i.e., changes of the business strategy) affect company results, and (3) compare these consequences and formulate a final advice based on this comparison. Through the use of scripting, the complex learning-task was divided into three phases (i.e., problem orientation, problem solution, solution evaluation) each focusing on one of the part-tasks. All groups were ‘forced’ to carry out the part-tasks in a predefined order; they could only start with a new part-task after finishing the earlier part-task. When group members agreed that a part-task was finished, they had to ‘close’ that phase in the assignment menu. This ‘opened’ a new phase, which had three consequences for the groups, namely they (1) received a new part-task (2) had to enter their new answers in a different window of the Co-writer and could not alter, but could still see, their prior answers, and (3) received an ER. For the three mismatched conditions, the ER did not change. Only in the fourth, matched, experimental condition, did the students get a new ER which was ontologically matched to the demands of that phase-related part-task. A description of the different phases and the matching ERs for the fourth experimental conditions follows. All other experimental conditions received the part-tasks in the same order (i.e., used the same script), but did not receive different ERs. [[skimx://slof2010design#9|p. 9]]

::Would have been interesting to compare with a non-scripted group that had access to all information and could do it in whatever order.:: [[skimx://slof2010design#9|p. 9]]

The problem orientation phase focused on creating a global problem representation by asking students to explain what they thought the problem was, and describing what the most important concepts were for coming to an advice. During this phase, students received the conceptual ER (i.e., a static representation of the knowledge domain; see Figure 2), which made two aspects salient, namely the core concepts needed to carry out this part-task and which core concepts were related to which other core concepts. Students could, for example, see that the ‘company result’ is determined by the ‘total profit’ and the ‘efficiency result’. This should make it easier for them to create an overview of all relevant concepts (i.e., to broaden the problem space), which should [[skimx://slof2010design#9|p. 9]]

support them in finding multiple solutions to the problem in the following phase. The low expressiveness of the conceptual ER supports the creation of a global problem representation which can be elaborated on in the following problem phases that contain part-tasks that require the support of more expressive ERs, that is: a qualitative casual and a quantitative problem representation. [[skimx://slof2010design#10|p. 10]]

The problem solution phase aimed at creating a scientific problem representation (i.e., explicating the underlying business-economics principles) by asking students to formulate several solutions to the problem. During this phase, students received the causal ER (i.e., a static representation of the knowledge domain; see Figure 3), in which the causal relationships - visible through the arrows showing direction of the relationship between the concepts - were specified. The causal ER also contributed to increasing student understanding by providing them with possible interventions (i.e., changes of the business strategy), each of which had a different effect on the company results. This should make it easier to explore the solution space and therefore should support students in finding multiple solutions to the problem. Students could, for example, see that receiving a rebate from a supplier affects the ‘variable part cost price’, which in turn affects the ‘cost price’. The conceptual ER is not expressive enough for this part-task because the relations in that ER were not specified and the students did not receive any information about possible solutions. This means that they had to produce the advice themselves, without having sufficient understanding of the underlying principles of the knowledge domain. The simulation ER used in the following phase has a quantitative character which supports testing the proposed advices, but is difficult to process without a properly developed qualitative understanding. [[skimx://slof2010design#10|p. 10]]

The solution evaluation phase aimed at increasing understanding of the knowledge domain with the aid of a quantitative problem representation. Students were asked to determine the financial consequences of their proposed solutions, and to formulate a final advice for the entrepreneur by negotiating the suitability of the solutions with each other. During this phase, students received a simulation ER (i.e., a dynamic representation of the knowledge domain; see Figure 4) which enabled them to manipulate the value of the concepts by clicking on the arrows in the boxes. When the value of a certain concept was increased or decreased, the simulation model automatically computed the value of all other concepts. The results obtained here should facilitate determining and negotiating the suitability of the proposed solutions and coming to a final advice. Students could, for example, test how a supplier rebate (i.e., decrease of the total variable costs) affects the ‘cost price’ and how this in turn affects the ‘company result’. Only the simulation ER is capable of providing this kind of support, because the relationships between the concepts in this ER were specified as equations (i.e., weight of the relationship). [[skimx://slof2010design#11|p. 11]]

According to Anderson and Krathwohl (2001), a knowledge domain consist of different knowledge dimensions which refer to the different ways (i.e., factual, conceptual, procedural) in which the concepts can be understood. Factual knowledge entails students being familiar with the concepts of the knowledge domain. Conceptual knowledge entails students understanding [[skimx://slof2010design#12|p. 12]]

the interrelationships between the different concepts of the domain. Procedural knowledge entails students knowing how to apply a certain technique or procedure and are capable of determining when applying that technique or procedure is appropriate. [[skimx://slof2010design#13|p. 13]]

When conducting studies in the field of CSCL, students are often working in groups. In such settings, researchers have to cope with several statistical concerns, namely (1) hierarchically nested datasets, (2) non- independence of dependent variables, and (3) differing units of analysis (e.g., Janssen, 2008). The latter concern is also relevant for this study because the dependent (e.g., post-test score) and independent (e.g., experimental condition) variables were measured at different levels, namely the individual and the group level respectively. Multilevel analysis (MLA) is a statistical technique suited to “appropriately grasp and disentangle the effects and dependencies on the individual level, the group level, and sometimes the classroom level” (Strijbos & Fischer, 2007, p. 391). To determine whether MLA was a suited technique for answering our research question we computed the amount of variance on the post-test score that could be accounted for by the group (e.g., intraclass correlation coefficient, Kenny, Kashy, & Cook, 2006). Of the total variance on post-test score 59% could be explained by the variance at the group level. This means that working in groups accounts for more variance on individual post-test scores than individual characteristics of the group members (e.g., age, sex). For this reason, MLA was used to determine the effect of experimental condition on post-test score. One-way MANOVA was [[skimx://slof2010design#14|p. 14]]

used for answering the second research question. Since there were specific directions of the results expected (see hypotheses) all analyses are one-sided. [[skimx://slof2010design#15|p. 15]]

The t-test showed that the overall post-test score of 90 students (not all 96 students were present when the pre-test and/or post-test were administered) was not significantly higher than the overall pre-test score (t(90) = 0.72, p > .05). There were, thus, no individual learning gains. [[skimx://slof2010design#15|p. 15]]

The groups in the match (i.e., part-task-congruent) condition outperformed the groups in both the conceptual and simulation conditions, their answers were more suited for a specific part-task, contained more justifications, and were more often correct. [[skimx://slof2010design#16|p. 16]]

According to Kirschner, Sweller, and Clark (2006), carrying out complex learning-tasks is an instructional method based on the epistemological content (i.e., methods and processes) instead of the pedagogical content (i.e., acquiring knowledge) of a knowledge domain. Although both the epistemological and the pedagogical content include factual, conceptual and procedural knowledge, students do not necessarily use the same cognitive processes (Anderson & Krathwohl, 2001). That is, recalling and grasping the meaning of concepts, principles and procedures is often regarded as prerequisite for the higher-order cognitive processes required for carrying out complex learning-tasks. Such learning-tasks consist of part-tasks demanding students to apply their understanding of the domain in order to analyze the problem, come up with proper solutions and evaluate their suitability and might be less supportive for acquiring more domain knowledge. [[skimx://slof2010design#17|p. 17]]

Ainsworth, S. (2006). DeFT: A conceptual framework for considering learning with multiple representations. Learning and Instruction, 16, 183–198. Anderson, L. W., & Krathwohl, D. R. (2001). A taxonomy for learning, teaching, and assessing: A revision of Bloom's taxonomy of educational objectives. New York: Longman. Barron, B. (2003). When smart groups fail. Journal of the Learning Sciences, 12, 307–359. Beers, P. J., Boshuizen, H. P. A., Kirschner, P. A., & Gijselaers, W. H. (2005). Computer support for knowledge construction in collaborative learning environments. Computers in Human Behavior, 21, 623–643. Bredeweg, B., & Forbus, K. (2003). Qualitative Modeling in Education. AI Magazine, 24(4), 35–46. Brna, P., Cox, R., & Good, J. (2001). Learning to think and communicate with diagrams: 14 questions to consider. Artificial Intelligence Review, 15, 115–134. Chi, M. T. H., Glaser, R., & Rees, E. (1982). Expertise in problem solving. In R. Sternberg (Ed.), Advances in the psychology of human intelligence (pp. 7-75). Hillsdale, New Jersey: Lawrence Erlbaum Associates. Cox, R. (1999). Representation construction, externalised cognition and individual differences. Learning and Instruction, 9, 343–363. Dillenbourg, P. (2002). Over-scripting CSCL: The risks of blending collaborative learning with instructional design. In P. A. Kirschner (Ed.), Three worlds of CSCL: Can we support CSCL? (pp. 61-91). Heerlen, The Netherlands: Open Universiteit Nederland. Duffy, T., Dueber, B., & Hawley, C. (1998). Critical thinking in a distributed environment: A pedagogical base for the design of conferencing systems (CRLT Technical report No 5-98). Bloomington, IN: Indiana University, Center for Research on Learning and Technology. Ertl, B., Kopp, B., & Mandl, H. (2008). Supporting learning using external representations. Computers & Education, 51, 1599–1608. Fischer, F., Bruhn, J., Gräsel, C., & Mandl, H. (2002). Fostering collaborative knowledge construction with visualization tools. Learning and Instruction, 12, 213–232. Frederiksen, J. R., & White, B. Y. (2002). Conceptualizing and constructing linked models: Creating coherence in complex knowledge systems. In P. Brna, M. Baker, K. Stenning, and A. Tiberghein (Eds.), In the role of communication in learning to model. (pp. 69-96). Mahwah, New Jersey: Lawrence Erlbaum Associates. Frederiksen, J. R., White, B. Y., & Gutwill, J. P. (1999). Dynamic mental models in leaning sciences: The importance of constructing derivational linkages among models. Journal of Research in Science Teaching, 36, 806–836. Gagné, R. M., Brigg, L. J., & Wagner, W. W. (1992). Principles of instructional design. (4th ed.). Forth Worth: Harcourt Brace Jovanovich. Hollan, J., Hutchins, E., & Kirsh, D. (2000). Distributed Cognition: Toward a new foundation for Human- Computer Interaction research. ACM Transactions on Computer-Human Interaction, 7(2), 174–196. [[skimx://slof2010design#19|p. 19]]

Janssen, J. (2008). Using visualizations to support collaboration and coordination during computer-supported collaborative learning. Ph.D. thesis, Utrecht University, The Netherlands. Jaspers, J., Broeken, M., & Erkens, G. (2005). Virtual Collaborative Research Institute (VCRI). Version 2.2. Utrecht, The Netherlands: Utrecht University. Jonassen, D. H. (2003). Using cognitive tools to represent problems. Journal of Research on Technology in Education, 35, 362–381. Jonassen, D. H., & Ionas, I. G. (2008). Designing effective support for causal reasoning. Educational Technology Research and Development, 56, 287–308. Kenny, D. A., Kashy, D. A., & Cook, W. L. (2006). Dyadic data analysis. New York/London: The Guilford Press. Kirschner, P. A., Sweller, J., & Clark, R. E. (2006). Why minimal guidance during instruction does not work; An analysis of the failure of constructivist, discovery, problem-based, experiential, and inquiry-based teaching. Educational Psychologist, 4(2), 75–86. Larkin, J. H., & Simon, H. A. (1987). Why a diagram is (sometimes) worth ten thousand words. Cognitive Science, 11, 65–100. O’Donnell, A. M., & Dansereau, D. F. (1992). Scripted cooperation in student dyads: a method for analyzing and enhancing academic learning and performance. In R. Hertz-Lazarowitz & N. Miller (Eds.), Interaction in cooperative groups: The theoretical anatomy of group learning (pp. 120-141). New York: Cambridge University Press. Reiser, B. J. (2004). Scaffolding complex learning: The mechanisms of structuring and problematizing student work. Journal of the Learning Sciences, 13, 273–304. Ploetzner, R., Fehse, E., Kneser, C., & Spada, H. (1999). Learning to relate qualitative and quantitative problem representations in a model-based setting for collaborative problem solving. Journal of the Learning Sciences, 8, 177–214. Schnotz, W., & Kürschner, C. (2008). External and internal representations in the acquisition and use of knowledge: visualization effects on mental model construction. Instructional Science, 36, 175–190. Simon, H. L., Langley, P. W., & Bradshaw, G. (1981). Scientific discovery as problem solving. Syntheses, 47, 1- 27. Spector, J. M. (2008). Cognition and learning in the digital age: Promising research and practice. Computers in Human Behavior, 24, 249–262. Strijbos, J.-W., & Fischer, F. (2007). Methodological challenges for collaborative learning research. Learning and Instruction, 17, 389–393. Seufert, T. (2003). Supporting coherence formation in learning from multiple representations. Learning and Instruction, 13, 191–203. Suthers, D. D. (2006). Technology affordances for intersubjective meaning making: A research agenda for CSCL. Computer-Supported Collaborative Learning, 1, 315–337. Van Bruggen, J. M., Boshuizen, H. P. A., & Kirschner, P. A. (2003). A cognitive framework for cooperative problem solving with argument visualization. In P. A. Kirschner, S. J. Buckingham-Shum, & C. S. Carr (Eds.), Visualizing Argumentation: Software tools for collaborative and educational sense-making. (pp. 25-47). London: Springer. [[skimx://slof2010design#20|p. 20]]

Van Merriënboer, J. J. G., Kester, L., & Paas, F. (2006). Teaching complex rather than simple tasks: Balancing intrinsic and germane load to enhance transfer of learning. Applied Cognitive Psychology, 20, 343–352. Van Merriënboer, J. J. G., & Kirschner, P. A. (2007). Ten steps to complex learning. A systematic approach to four-component instructional design. New Jersey: Lawrence Erlbaum Associates. Vekiri, I. (2002). What is the value of graphical displays in learning? Educational Psychology Review, 14, 261– 312. [[skimx://slof2010design#21|p. 21]]


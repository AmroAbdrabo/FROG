h1. Network Enabled Scholarship: Configuring research to exploit web infrastructure
//[[http://cameronneylon.net/|Cameron Neylon]], Advocacy Director at PLOS]]//

{{pages:network_enabled_scholarship01.jpeg}}


h2. Background
Began with traditional academic career, got into OA (2003). 

2012 - tipping point, something that is happening right now. [[http://en.wikipedia.org/wiki/Research_Works_Act|Research Work Acts]], and its failure to overturn [[http://publicaccess.nih.gov/|NIH public access policy]]. Finished with [[http://blogs.nature.com/news/2013/02/us-white-house-announces-open-access-policy.html|White House memo]], single largest increase in access to publicly funded research in history, will happen later this year.

Explosive growth of [[http://www.plosone.org/|PLOS One]], largest journal of the world, publishes more of every biomedical funder in the world than any other journal, example: [[http://www.wellcome.ac.uk/|Wellcome trust]].

{{pages:network_enabled_scholarship01.png}}

[[http://www.biomedcentral.com/1741-7015/10/124|Anatomy of open-access publishing]] - we can reach 50% OA in 2013 (Cameron's guess). 

No long a question of if, but how? Discussion about the best route. About when - speed? And why - worth reflecting about. 

h2. Agenda/how do we argue our case?
What is our agenda, what is it we are trying to achieve? About...
  * letting people read things
  * letting people use things
  * making science more effective in terms of funders

Kinds of arguments
  * Hippie-ish argument - We all pay, should have access. Doesn't easily change the world
  * Business argument - given the amount of money being spent, value for money, quality of service, sustainability
    * Impact - demonstrate that research has an effect in the wider-world. Big in Europe. 
    * We are the customer
    * The product is research outcomes (rather than outputs).
    * Problem for national governments investing - research is spread globally?

h2. Examples
h3. Math
[[http://gowers.wordpress.com/|Tim Gowers]] - Fields medalist (mathematics). Interested in research process. Collaborative research not common in mathematics -- could a collaborative approach be as powerful in math as in other sciences. Proposes [[http://gowers.wordpress.com/2009/02/01/a-combinatorial-approach-to-density-hales-jewett/|a problem that he can't solve himself]]. //"Can we show that this proof is worth pursuing?"// 

150 mathematician's, some Fields medalists, some school teachers - over a month, thousands of blog posts, created an outline for a mathematical proof, of a different kind from what he initially outlined (more general). 

<blockquote Tim Gowers>"It feels as though this is to normal research as driving is to pushing a car".</blockquote>

h3. Galaxies
Classifying galaxies, crowdsourcing science. [[http://www.galaxyzoo.org/|Galaxy Zoo]]. 100 galaxies could get you a paper in 1970, now we need 10,000 - do statistical surveys. One PhD student classified 50,000 pictures during his graduate studies. Not good enough statistical samples. Had a million galactic images available, data was not the problem. Over 3 months, 300,000 people classified the million galaxies three-four times over. Single largest human-curated visual data set of this kind of images that had ever existed. Not only enabled new kinds of statistical studies on this data by itself, but also new research on computer vision and automatic classification.

h3. Historical literature
Gandhi: Wrote "Indian Home Rule", published with "No Rights Reserved" - enabling translation into many Indian languages.

Corelli: Italian music imported to England, reprinted again and again. The reason we have access to it now?

h3. Policy-maker access
Economics papers are open access (Repec), sociology, anthropology etc isn't. Not accessible to policy consultants both for their own consulting, and to copy and include in reports to policy makers. 

h3. Wikipedia as portal to research
[[http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0044271|PLoS article]] about a monkey making interesting sounds... 87k views in a week. Why? [[http://en.wikipedia.org/wiki/Lesula|Wikipedia article]], live 9 hours after the article in PLoS published. Populated with content from the article, including the audio track. Person who write WP article had no connection with the authors. Only possible if truly OA. 

Wikipedia is the single most important form of public engagement with research that exists.

h2. Common success factors
  * Successes create scale
  * exploit networks, at web scale
    * turn all of our assumptions about how communications work, upside down
    * we think about how to make one connection at a time - useful, but missing the point
    * when the scale gets so big (3.6 bln on the Internet) - doesn't matter that a vanishingly small percentage of people care about your stuff, because at that scale, even that group becomes huge
    * with scale, it's far more likely that you will make that connection with people you don't know, and had never thought of as interested in your research
  * ease of transfer

As service providers, we need to 
  * how do we deliver scale
  * create networks
  * reduce friction

h3. Steps
  * Access is the first step, necessary but not sufficient
  * legal rights, interoperability
    * health minister in a Francophone African country, who is blind, has no access with Creative Commons No-Derivatives
    * commercial policy consultant who wants to deliver a copy of the research paper with his proposal, NC doesn't work
    * incompatibility between GFDL etc
  * technical usability
    * we're rubbish at this
    * need standards, formats, exchange protocols
    * apply to machines too - they need to tell whether they're allowed to read articles, be able to exploit scale

All of these have to scale - to web scale. And enable the unexpected. 

<blockquote>We don't know where the new advances are coming from, they will be unpredictable, but never an accident. You can't predict one throw, but we know the distribution. And when it comes to research, we make the dice, and can roll them more than ever before.</blockquote>

We can manufacture serendipity. If we choose not to, we're not discharging the responsibility to the people who are funding us. 

h2. Architecture
  * Needs foundations
  * Rough consensus

[[http://cameronneylon.net/blog/github-for-science-shouldn%E2%80%99t-we-perhaps-build-tcpip-first/|"Github for science? Don't we need TCP/IP first?"]]

{{http://yupnet.org/zittrain/images/fig4-1thumb.jpg}}

(from Jonathan Zittrain's book, CC BY-NC-SA)

**Research version by Cameron:**

{{pages:network_enabled_scholarship02.png}}

But we're much closer today. [[http://impactstory.org/|ImpactStory]] pulling in from [[http://orcid.org/|ORCID]], [[http://odin-project.eu/|ODIN]] glue between [[http://www.datacite.org/|DataCite]] and ORCID, [[http://figshare.com/|Figshare]], etc. Someone will build something in the next 6-24 months, and people will say "It's too easy, too simple". Like they said about the web, RSS, TCP/IP, etc.

{{pages:network_enabled_scholarship03.png}}

h2. Q&A
  * Can we quantify the ROI on serendipity? 1940-1950 most productive decade in research, because the government took control of research (counter-argument). 
    * Can't quantify serendipity, but look at multiplier of having open data, some data on this (Hubble space telescope). Craig Venter's closed genome project vs the open publicly funded project. Both generated enormous return on investment (100x), but the return on the publicly funded project was 35% greater.
  * Discovery, but what about just doing science, recording each experiment, etc?
    * Total cost of research cycle - doing research: 80% (a few years old). 2nd biggest cost: non-cash cost of peer-review, 35% of cost of scholarly communication cycle. 3rd largest: non-cash cost, people finding what they need to read. Huge uncaptured value in facilitating discovery for researchers.
  * [[http://www.ncbi.nlm.nih.gov/pubmed/19247851|Canadian study about NSERC]] - cheaper to just give money to everyone. But there is a value in the peer-review process, scientists sitting around the table and trying to figure out what's important. 
  * Right now we have industrial lab equipment manufacturers as the choke point if we want to optimize data gathering and sharing in labs. 
  * All Facebook "likes" for T&F journals aggregated to the url [[http://www.tandfonline.com/action/cookieAbsent|absent cookie]]. Problem with huge amounts of platforms, publishers etc with different (/missing) standards. 
  * How do we change the system from within (tenure process, incentives)?
    * Easy to obsess about what people did to succeed five years ago, whereas your own trajectory is a few years down the line. PLOS One is already 6% of the output of the NIH, 15% of the Wellcome trust, in 2012. Things are changing fast. 
    * One thing researchers can do: Include alt metrics in your CVs, applications - 150,000 YouTube views, 10,000 downloads, etc. 
    * Peers often more conservative than dean. Evolutionary pressure of tenure: people who are good at getting tenure.
    * Libraries biggest obstacles to change, because they keep signing these deals. Biggest obstacle to libraries changing, is academics demanding journals. Academics and librarians need to talk together more.
    * More innovation at tier-2 institutions, tier-3 feel like they are on the way out, tier-1 are secure, don't need to change. In Toronto, for the tech startup scene: don't talk to UofT, talk to Ryerson.  
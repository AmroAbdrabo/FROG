h1. Kindle highlights

We begin with a comparison of face-to-face and online collaboration, since we have studied the former in great detail and need to understand how online collaboration differs. This study compares Proximal (face to face) with Distal (synchronous collaboration via networked software) conditions. **(loc: 23-25)**

Both versions of the software support deixis by causing the color of objects to change when one passes the cursor over them, enhancing the deictic value of the cursor. The Distal version of the software replicated these color changes to the remote display. In this manner we attempted to enable the use of the knowledge representation as a resource during conversation in the Distal as well as Proximal condition. **(loc: 55-58)**

Analysis process Video/audiotape of the proximal sessions were transcribed by hand. The software generated transcripts of the distal sessions automatically. Transcripts were divided into “segments,” each consisting of a verbal or typed utterance (multi-propositional utterances were divided into individual segments) or a change to the representation. See Suthers & Hundhausen (2001) for details of coding. Then we performed a content analysis of participants’ learning processes by coding all segments in the 20 transcripts into the following mutually exclusive “topic” categories: • Evidential relation. These segments consider whether data and hypotheses are consistent, that is, whether a data item supports or conflicts with a hypothesis. For example, the segment “That’s for the genetics hypothesis” would be coded as evidential relation—consistency. • Epistemic classification. These segments classify information as either empirical or theoretical—that is, as either data or hypothesis. For example, the segment “Let’s make a hypothesis about toxic drinking water” would be coded as epistemic classification. Likewise, in the Graph software, the action of clicking on the “create data” button would be coded as epistemic classification. • Hypothesis statement. This coding was applied when participants stated a hypothesis concerning a possible explanation for the disease without labeling it as a hypothesis (e.g., “Might be a combination of both”). • Metacognitive. In these segments, participants step back and either assess what they know so far (e.g., “We know that they used the drinking water for the fadang, to prepare the seeds”), or identify information that is needed but lacking (e.g., “See, but it doesn't say that these admission records are patients that have the disease”). • Warrant. These segments provide justification for an evidential relation previously cited. For example the second half of, “That supports the aluminum hypothesis, because Irian Jaya was 4 Paper presented at AERA 2002, April 1-5 2002. New Orleans found to have higher than normal levels of aluminum in the soil” would be classified as a warrant. • Tool talk. These segments discuss some aspect of the software. Participants might, for example, ask how to complete some specific task with the software (e.g., “How do you get this out of the way?”); they might complain about the software (e.g., “Oh my, what's wrong with this thing?”), or they might share their emerging understandings of how the software works (e.g., “If we click on this we can see it”). • Domain talk. These segments discuss the domain of the science problem that participants are exploring. Since this is the loosest of the Topic categories, it had the lowest precedence; we coded segments into this category only if they could not be coded into one of the five categories above. For example, “Northern Guam is a low limestone plateau” would be coded as domain talk. • On-task. These segments did not fall into any of the first six categories, but could still be considered on-task. For example, “Let’s go to the next page” would be coded as on-task. • Off-task. These segments were deemed to be unrelated to participants’ learning task. For example, “What did you do last night?” would be considered off-task. In addition, we coded topic segments with “modifier” categories, according to whether they were • Verbal or representational—spoken or expressed in the chat tool, versus represented using the software; • Recited or non-recited—quoted verbatim from the information pages, or not quoted; • Introduced or repeated—the first occurrence of an idea within a given conversation, or a reintroduction of an idea already brought up within a given conversation. **(loc: 68-98)**

The Distal discourse representation may have also affected communication on the receiving end. Because chat messages appeared in small black lettering in the bottom corner of a screen dominated by colorful graphics, effort was required to check regularly for new chat messages. **(loc: 190-92)**

This slower and more complex “chat” discourse mode, combined with its lack of visibility on the screen, may have discouraged Distal participants from discussing the problem or checking for agreement before posting items as much as Proximal participants. These factors may have also encouraged Distal participants to bend the rules a bit to get their messages across. Several pairs used the data and hypothesis bubbles to post messages to each other, possibly to make them more visible. For instance, one pair posted off-task banter such as “Audrey is a dweeb” and later removed it. Another pair posted on-task questions, such as “What should we do now?” and “I don’t know what the answer is.” Still another pair posted domain questions such as, “What is causing this disease?” and linked them up with legitimate data and hypothesis bubbles. (We adjusted our statistical counts of epistemic classifications and relations so that they do not include such items). **(loc: 192-99)**

::interesting to think abt new ways of displaying chat etc. link w paper on role of human facilitators and backchannel:: **(loc:  199)**

Social factors may have also played a role in the results, although this could not be substantiated without personal interviews of the participants. Physical distance may have lessened the social pressure for agreement that often accompanies verbal collaboration. Distal participants may have felt they could “get away” with adding items to the graph without discussing them as much, since their partners might not immediately notice changes to the diagrams, nor take the time to type out challenges to the representations. **(loc: 199-203)**

The illusion of privacy suggested by the Distal discourse chat tool seemed to encourage Distal participants to engage in more off-task discussion. Although a research monitor was in the main room for both studies, chat was not reviewed until after the students had left. Distal discourse was peppered with “chat slang” and email jargon popular in a recreational context. Participants often used the chat tool to send off-task jokes, laughs and emotive faces. Off task banter made up 8 Paper presented at AERA 2002, April 1-5 2002. New Orleans 5% of the total communication in the Distal condition, compared to 3% in the Proximal condition. (Although some emotives could relate to the problem, such as a sad face indicating disapproval with a represented item, these emotives weren’t coded, to avoid drawing unwarranted assumptions about their meaning). **(loc: 203-9)**

Physical proximity may have also influenced the number of data and hypothesis items added and later removed. Distal pairs often posted items independently without negotiating first. As a result, they sometimesended up with duplicate data and hypotheses. Similar items were later deleted, and negotiation to determine which partner’s item would remain on the diagram was a frequent focus of discourse, **(loc: 209-12)**

In the Distal condition, discourse often took place within the graphs in two ways: (1) participants often proposed new items or relations by creating them in the graph medium, whereupon chat focused on approval or disapproval; and (2) participants used the graphical representation in place of the chat tool to send a message that was deleted. The Graph was also used in a manner peripheral to discourse, when a participant independently modified the graph amidst unrelated chat discussion. This created a need for the removal of duplicate or similar items created independently by each partner, and some discourse focused on the negotiation of whose item would be removed. **(loc: 246-51)**

::interesting how important the delete function is whereas proximal would only post when they really agreed:: **(loc:  251)**

::would be interesting if they also had wiki like history of deleted items and undo button to make delete more part of the iterative process:: **(loc:  270)**

::wonder how this would have been different if using skype voice instead of chat:: **(loc:  312)**

